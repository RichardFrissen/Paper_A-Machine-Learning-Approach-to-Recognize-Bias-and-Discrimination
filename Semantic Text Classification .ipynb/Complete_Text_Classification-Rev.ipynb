{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "requested-waterproof",
   "metadata": {},
   "source": [
    "## 1. Import libraries and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "# import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "# import nltk\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from statistics import mean\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# from flair.embeddings import WordEmbeddings\n",
    "# from flair.data import Sentence\n",
    "# from flair.embeddings import TransformerWordEmbeddings\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seed\n",
    "seed = np.random.seed(1)\n",
    "\n",
    "\n",
    "# Select Spacy model\n",
    "# Efficiency\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Accuracy\n",
    "# nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbe10b-e6fc-47bc-8623-737353262b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################### LR #########################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7213ef-4cb3-471b-abf5-476b51d45835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-christopher",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_bert_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a759a-62f0-40c8-a381-944f2462ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c74e9f-6497-4b7f-a494-9a566688083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9d0b6-72c3-4c32-8c01-048b321bd87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f7e11-ce66-4cde-82f1-6141f567538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('bert_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934790eb-8402-46d4-abed-021ff7baf8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e36a5-5109-41bd-80ab-bb1f454bf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('bert_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c5f8b-b7e2-4e57-a041-a455b67dc6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc7f78-414e-4333-afb8-fa91126d7ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6751eac-557d-40c6-8299-65e384c3e6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('bert_results_lr.csv', index = False)\n",
    "results_cv.to_csv('bert_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045ffca-48ac-4268-9cdc-e22174a505d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a52d24-0c96-4aee-bfa9-bce7753bb7e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_elmo_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a38386-c238-4f04-ab93-5af4d27fb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da6db8-872d-4235-b057-5c9ef7a88305",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f851802-3d36-48b1-8f07-1e91cd762be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05d607-484e-410c-a610-b77c2b4d8f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c7d2c-4075-4c00-900c-2f095565f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3f0e9-9ad3-401c-a753-932361b3a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('elmo_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d09b4e-c2bb-4255-a673-26f41742510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebc0686-56e5-4c97-a2ce-b558bb9f1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=2, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f389aaf-a32f-4a5b-a0c2-d75a75611b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('elmo_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cade55-5249-408b-8b42-ccb9ded80f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd4570-769b-4008-b38d-459e56e2e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c515a3-26d9-4324-a339-1c6170107a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd109e9-4c32-4e4b-a047-207db9de3cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('elmo_results_lr.csv', index = False)\n",
    "results_cv.to_csv('elmo_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0ec60-c42d-4868-98eb-209f5fc469e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268e87b-7278-423a-b401-75bc59c2b5e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_glove_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627312c-0c57-4206-b629-ecb97993feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8ed0a-678a-4ba8-9e62-1a085faa7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2dad-d559-4fc2-bc68-2e976d6dbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbec770-90a3-4209-aa7a-d30d5820ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcad27f-a0a3-4fe5-aca3-47defafc6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d58da-d1ee-4ca2-92a7-789dd3c57974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('glove_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24134a02-bb36-4ac9-ab6f-e6e9665828df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fd8d3-8e30-40af-a0ce-42289eacf577",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f33e6-b714-4b6a-a0b4-64981bf95259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('glove_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436fcde-0c3c-40c2-9e7b-7b8b5fe533b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62500c1-4edd-49f3-8715-2cc13a4cca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8e1ad-7d46-4304-9508-d363a190cad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7c858-9b58-4d30-9e51-4e58d8c6e0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('glove_results_lr.csv', index = False)\n",
    "results_cv.to_csv('glove_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713297c8-6f67-4a7a-9511-2dd31da05724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c74e67-a52c-4e48-918b-86e6ae6c5e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_word2vec_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3366c-b2cb-43ef-a33f-2d63ed047d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ba082-23d6-4cae-8d10-9ad235ff85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a2a63-1617-496f-8a44-81521c4fee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acad2e-a663-4181-9715-41499e4733cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaf32a-6c99-4437-bd70-36f7868334a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084f357-2aba-48a1-abdd-faa843dce592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('word2vec_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c00ede-2891-4cbc-99b9-4511e5b0d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef269cc-054d-4c2e-a20e-6c6d8c3e550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324eb2c-8436-4315-840e-804e0beeb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('word2vec_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d35d92-0488-4a1a-a3a1-63fa069811e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01a8aa8-1b31-44d3-9939-9ea06da940d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b788a2b-e52c-4757-be87-be54cbe79e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117f98a-50ed-4e2f-8854-a2a69e97961d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('word2vec_results_lr.csv', index = False)\n",
    "results_cv.to_csv('word2vec_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b90534-55b1-4afc-aaeb-277089034956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b6ed0-3029-4521-b191-284338d72391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_flair_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c09cd8-37e0-4a21-9189-49d3107c61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfff3f31-a6ad-4c1f-9948-e6d117d78ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00f1e6-19ff-49f0-ab92-72d4e936d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c54eac-fd02-4bf6-b822-91b1ecac7b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312168c-ce3e-40dc-a97b-f988b75149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166359f-f6a8-46cb-950e-0c8ae704cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f494c9e-ed47-43d8-a659-d035877bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7e94c-e55f-49d2-b8aa-811bdf6f74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b8ea7-3a2c-466a-a17a-0800edee3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc4778-fad8-4135-afca-0a6fb770bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16091470-26b5-4a45-8d8f-0af669c34652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af976a66-98e0-4698-a251-f72042e343f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc817be-02ff-4b29-8e79-485736e5a92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a96fb8-33b0-4ece-aabd-56fee707e2c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('flair_results_lr.csv', index = False)\n",
    "results_cv.to_csv('flair_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f797f-3a33-41ec-bb78-beccf7152e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### LR - fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e14f6-0d04-4591-b0af-25bafbd6938f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_fasttext_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e995358-1a30-4594-8f43-4e390bf7372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e3a5d-b8e0-4c6e-b248-b4b8b2deda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea01252-322d-4945-a297-69780adb24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6363d-6eb2-4e1b-8fc6-c38b4065ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325001e-0390-4da3-959e-3fa965d3e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c1289-59c0-4d9a-ab5e-3deb30e4952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('fasttext_baseline_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_baseline_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4db1e7-678e-4abd-96e7-e53c6b6dae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bce39-4882-4bee-9055-f7896fb60eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db35da1-4cbe-42cf-8437-bb99b339fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('fasttext_lr_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_lr_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f92248-0354-4005-9c51-fc70b8a703cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649cf8b9-1dab-42bf-87b1-1756efbdd93d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_cv_results_lr.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_cv_results_lr.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bf9a0-1b4b-47ab-a82b-8c7b6f4c30cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_results_lr.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_results_lr.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26036c7a-6713-490f-8ed2-24b3c94ab7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('fasttext_results_lr.csv', index = False)\n",
    "results_cv.to_csv('fasttext_cv_results_lr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db695c-1249-48dc-b7cd-d3d596bd82f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################### DT #########################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110ce52-68bd-47d0-bf07-92ed5ea54106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67550515-9fb2-448f-8774-fa184ff8b99d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_bert_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192d883-fddb-4275-bc59-adcc26722841",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5da8e-615e-4954-b9d3-28e642b0e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9af792-6d59-4cb2-b81d-4014ec6ba1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6f440-210b-4650-8de3-683dd94e6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a69c69-bb4e-4380-b67c-592f4c9f289d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fb490-535b-4bf7-979b-2b2b9241eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('bert_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5dd00-7aa7-4ee8-8a15-3e899a5a955c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57086883-32ed-4165-abd5-c5487eb65338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff9f36-fed5-4de0-bfb3-a5866f1f6d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ec3f5-2719-410a-ad6f-78a9f1468f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('bert_results_dt.csv', index = False)\n",
    "results_cv.to_csv('bert_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e1de7-d06f-4596-9d81-32b43c0a524d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952ea56-3b47-49ca-a262-24e04d0a1849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_elmo_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebdfaf-0c80-4a89-939c-f6475645e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc961d6-b17f-4c89-a734-797590b720d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428346a4-e1d9-4059-b56d-6dc297ee3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46bf4e-fde7-4075-859b-d82077337fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0299da8-5953-4465-a0c1-c2b7a937b383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=2, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa12042-a63c-4917-83d3-e9b1c85a515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('elmo_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67185e9-42a7-46bd-9096-be37c7d8e973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed8c0d-aa16-442a-bb9d-331b738fd5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a7df9-026a-497e-9f60-3f0ee9341228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ab33cc-9da4-47dd-b933-d694541c3fd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('elmo_results_dt.csv', index = False)\n",
    "results_cv.to_csv('elmo_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31af801-80f9-4ca7-8eb5-085c6acd4ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385e616-973f-4866-8b54-a2d0895cdd7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_glove_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faedec7-a03d-4a4d-a664-63b6471c25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c321e-239d-4733-bd1a-8d1704cbd55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf40c2f-f1d9-4ac2-a940-a4f92f9e0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17297f1b-2ef2-4f3f-98f8-451f35dac5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaafaf-9bd3-467c-a0f5-84757cf0010d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd964a1c-e5ba-4484-9049-c71f85519943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('glove_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cc1e9-f2e7-43fc-b52a-eaa4e0d9ace0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f345631-9c1b-40df-9371-23e1ad94bbfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c276b6c-c2a4-48b2-9ec0-9bd82801984c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe95b1-c403-48ae-9ff9-556621c0389f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('glove_results_dt.csv', index = False)\n",
    "results_cv.to_csv('glove_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bafcc4-c955-4964-9363-39f314a37c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31fc2cd-8a86-4f97-bff3-34763f8b8ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_word2vec_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41591cd-9bad-45b7-890e-69fe0e165bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab871c9-6285-4b74-a317-58a807486f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48db724b-bd14-4226-8c09-afba4e9937ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2ac18-13eb-4551-a858-f4a443b23aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c22b2-ba60-49bc-be81-400235e4a02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ede44d-d3f1-49ac-8421-5c01bcfcd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('word2vec_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b5386-a69c-40b2-ae40-6d0cb4e4d888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25debc2-38c7-454c-9bfb-e654cd914ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5546c45-202c-4e2d-82c2-369c7e1c2ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf5a34-d58e-41f3-ba8f-93ab54e78e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('word2vec_results_dt.csv', index = False)\n",
    "results_cv.to_csv('word2vec_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cde71-2aa2-4617-82dd-4d6607dbca91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf08b8-c7d8-47e3-bb90-8ce1e21c3732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_flair_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475b38d-4204-4693-9a64-fd2f6896fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee9f06-ab44-4da0-9741-54af9d0e3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7987b60-328e-4586-b1b8-f6087cd65fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10a616-b743-4b8a-b6a3-a9f5950577dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0a14f-75b8-4796-bc2f-a01a12d2bb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=2, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa11ded-b19f-40a7-a27d-ff560e22c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5960f-7a2a-48ba-b568-fb261202011e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25517e-c02f-48a5-9aa4-10c2a2955bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb2dd7-1e46-4f82-be47-0f2747c30538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a1980-d06b-4ebf-90fd-3d1f29fe3a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('flair_results_dt.csv', index = False)\n",
    "results_cv.to_csv('flair_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be02dbb-d188-41de-b57b-87a851eb26ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### DT - fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0425e0-d126-4879-807f-352ed9c553bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_fasttext_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc72b9-fc27-4c1c-b280-77e015da3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad9aa2-83cc-4df0-8e0b-b7fe3bd483f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565866d1-3ad7-42ee-a32e-8d49b5d9e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16ec20-382a-438e-8cc3-ca9a057b31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d41d8c-65fb-44af-b863-7b284babbe7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eae80d-2e24-473a-8368-7253ce56274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('fasttext_dt_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_dt_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4056a148-d7cc-43a8-9dd0-f27cb2eb717d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65811ff4-fc5d-49af-9ccd-deb302c61649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_cv_results_dt.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_cv_results_dt.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a2cf93-053c-40e0-a824-63d5f4ddc13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_results_dt.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_results_dt.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a6fe7-7b00-43ac-af5a-797eed6bef5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('fasttext_results_dt.csv', index = False)\n",
    "results_cv.to_csv('fasttext_cv_results_dt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58189a-c63a-4fd6-8e1d-e2c9fe0945cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "######################################################### NB #########################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213cd8f-c13f-4e75-a704-2bce2bf9f69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf558fe-3418-4af7-883c-f9492fe22403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_bert_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd590382-a410-4f83-99fd-bd7e2a092dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba286a9-11ef-46ed-9154-e533963a23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37a6f4-d1a2-41e3-977f-d48adcb378a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af2764e-1f3d-4fc9-a484-1df93386413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9b706-67c7-456a-82b6-692c082bcd40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2897c-fc60-4ecd-928f-0515f09a0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('bert_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b9628-c137-4b93-82d6-3a8d56bcad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368f291-6467-4b10-a457-0da1dbd17f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632ae5f-cd55-4982-99b0-514d88ec9119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('bert_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('bert_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9268da2-51b3-41e8-9ea5-01a5275f0f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('bert_results_nb.csv', index = False)\n",
    "results_cv.to_csv('bert_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff74bbe-3c85-4f99-a0da-4074de994cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6c713-117e-40ba-a9e9-558f20515230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_elmo_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae39497-9d70-450c-8800-b3c8db018b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f1751-926f-464c-90f3-7254dad34c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90c244-6448-486a-af5e-05a3593f1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e66dfdc-1fba-487a-b660-e903adaef4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d824c-5f4e-4dbf-b080-d560a573cfe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=2, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f2956-425a-41a7-90a3-d259aea68c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('elmo_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5d86f7-f48e-4471-9455-e2b1d0ad2ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc2a2c-5a0b-43a7-9331-2cab5a1e1e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783810c-54e4-4926-9e9b-de715c26fed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('elmo_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('elmo_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6fedd-4d36-424e-8261-c23a825ad80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('elmo_results_nb.csv', index = False)\n",
    "results_cv.to_csv('elmo_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74b669-da61-49e5-ab9e-38af16f7ec44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd75fb-f065-4c8d-a5db-365bc6bfe9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_glove_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87604ff-3a56-4d3c-9b3e-9b68f9cab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ce143-6d41-42e8-8749-3d66bae6360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915594f-0707-463a-b837-f3644f142279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72ea2d-1722-4fb5-9377-5cd24d30a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdc399-7dc0-4ffb-b6f8-e86a83858b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682b744-e039-4df0-a873-54d7aa040879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('glove_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1baac-a4c3-4e6f-96b1-8614b326634c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e1fb2-bf62-4ec8-b1e9-fc7087320982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d163920-2131-4db0-89e4-72ddac0342a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('glove_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('glove_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a27e98-d9ac-438b-8529-84b14d8d5487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('glove_results_nb.csv', index = False)\n",
    "results_cv.to_csv('glove_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28375e49-4e5c-4875-a101-7433c96170a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6563c4-907b-419e-9f1e-430ce729676a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_word2vec_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b9b1a-5d95-401f-953f-486653d58b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca9209-ed1c-4b4a-b4cd-1aabe9f1a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635512e9-558c-41de-a880-8c7ae6cbcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53a412e-10eb-4211-ade7-8927861fe891",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde121a-042f-4b8e-adf3-9dd3cb988866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c3b66-0709-4ef2-bb89-166196b38517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('word2vec_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ced66-0e80-47db-bef6-0421245cca1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd231134-e629-41da-9b5c-a810eb5b220b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc03ad4-c3d2-40b2-9268-edbdc1206d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('word2vec_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('word2vec_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d996f-3fe0-4b6c-8e26-fc244d795ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('word2vec_results_nb.csv', index = False)\n",
    "results_cv.to_csv('word2vec_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66e603-a97d-499d-b23b-7160bee360c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66120c-0478-4a9b-8283-7c697ce5684d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_flair_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b39c9b-7fc9-49ab-a115-f82329ce13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41616842-1f74-4df3-a5ef-d4f2f99b0f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728eee8-7cd4-4b0f-ac0a-70a62356a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37760f05-ea50-4325-8e15-a4c94585061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a3689-46a5-46f9-844f-de3a798dc78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=2, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8eede-915c-43ba-b1de-bb5d75e9cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84fd2a-7a84-4379-adf4-16a4f0850af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba64fac-e85c-4907-ad8b-7c3598daa580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9962cc0-939d-48a6-8833-3163ac952db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02254aa0-19b4-439b-acbb-9dbdbcfae4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('flair_results_nb.csv', index = False)\n",
    "results_cv.to_csv('flair_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee65c7b3-b47d-43f1-9b58-260c273aa25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################### NB - fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3410296-56c6-4fa4-89dc-c771e9a47ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "# data.to_csv('data_features_full_complete_wordembedding_bert.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_fasttext_complete.csv', na_values=['nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46256104-b679-4b36-83ee-161d0851a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1511fa-5f26-4d21-b40f-2bfe04ec446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8952c1-1def-458e-8a36-a68b944f9ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88efd4e0-72b3-4706-9a42-b3d86d575e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee5c70-b278-4d3a-a3e5-e9baec16d3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54e253-9f03-4f58-a382-87ccd265fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('fasttext_nb_rev.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_nb_rev.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0bd6d-05b7-419a-aaf0-b12574c5fb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd4abe-0a73-42ce-bd9d-6cb3f83b76ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_cv_results_nb.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_cv_results_nb.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c33cb3-761e-45d4-adfc-1200282cbe84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('fasttext_results_nb.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('fasttext_results_nb.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91596730-0664-4e3e-ab97-74db4676fa8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "results.to_csv('fasttext_results_nb.csv', index = False)\n",
    "results_cv.to_csv('fasttext_cv_results_nb.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55a761-f655-4db8-a4c1-1c5e66de10a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
