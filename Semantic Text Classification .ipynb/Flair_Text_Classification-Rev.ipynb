{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "allied-desktop",
   "metadata": {},
   "source": [
    "## 1. Import libraries and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "# import gensim\n",
    "# import gensim.downloader\n",
    "# from gensim.models import Word2Vec\n",
    "# from gensim.test.utils import common_texts\n",
    "# from gensim.models import Word2Vec\n",
    "# from gensim.models.phrases import Phrases, Phraser\n",
    "import nltk\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from statistics import mean\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set seed\n",
    "seed = np.random.seed(1)\n",
    "\n",
    "\n",
    "# Select Spacy model\n",
    "# Efficiency\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Accuracy\n",
    "# nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns and read annotated data\n",
    "columns = ['Token', 'Label', 'pos', 'ent_type', 'is_alpha', 'is_ascii', 'is_digit', 'is_lower', 'is_upper', 'is_title', 'is_punct', 'is_space', 'like_num', 'is_oov', 'is_stop', 'like_num', 'lang', 'sentiment']\n",
    "data = pd.read_csv('FULL_Annotation_data_output.tsv', sep='\\t', nrows=50, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Generate linguistic features for each token\n",
    "\n",
    "def feature_extraction(input_column):\n",
    "    features = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "    for i in input_column:\n",
    "        i = str(i)\n",
    "        doc = nlp(i)\n",
    "        word = i\n",
    "        for token in doc:\n",
    "            features[0].append(token.pos)\n",
    "            features[1].append(token.ent_type)\n",
    "            features[2].append(token.is_alpha)\n",
    "            features[3].append(token.is_ascii)\n",
    "            features[4].append(token.is_digit)\n",
    "            features[5].append(token.is_lower)\n",
    "            features[6].append(token.is_upper)\n",
    "            features[7].append(token.is_title)\n",
    "            features[8].append(token.is_punct)\n",
    "            features[9].append(token.is_space)\n",
    "            features[10].append(token.like_num)\n",
    "            features[11].append(token.is_oov)\n",
    "            features[12].append(token.is_stop)\n",
    "            features[13].append(token.lang)\n",
    "            features[14].append(token.sentiment)\n",
    "            features[15].append(len(word))\n",
    "    return features\n",
    "\n",
    "features = feature_extraction(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert list to dataframe\n",
    "features = pd.DataFrame(features)\n",
    "\n",
    "# We need to transpose this dataframe first\n",
    "features = features.transpose()\n",
    "\n",
    "# We concat the annotated data with the linguistic features\n",
    "data = pd.concat([data, features], axis=1)\n",
    "data.columns = ['Token', 'Label', 'pos', 'ent_type', 'is_alpha', 'is_ascii', 'is_digit', 'is_lower', 'is_upper', 'is_title', 'is_punct', 'is_space', 'like_num', 'is_oov', 'is_stop', 'lang', 'sentiment', 'word_length']\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "data.to_csv('data_features_full_dataset.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_dataset.csv', nrows = 500000, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-expression",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init word embedding\n",
    "embedding = FlairEmbeddings('news-forward-fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Generate word embeddings for each token\n",
    "\n",
    "def flair_wordembed(input_column):\n",
    "    flair_result =[]\n",
    "    counter = 0\n",
    "    for i in tqdm(input_column):\n",
    "        counter = counter +1\n",
    "        try:\n",
    "            i = str(i)\n",
    "            token = Sentence(i)\n",
    "            embedding.embed(token)\n",
    "            for token in token:\n",
    "                result_array = token.embedding\n",
    "            result_list = result_array.tolist()\n",
    "            flair_result.append(result_list)\n",
    "        except KeyError:\n",
    "            flair_result.append(np.nan)\n",
    "        except TypeError: \n",
    "            flair_result.append(np.nan)\n",
    "        except IndexError:\n",
    "            flair_result.append(np.nan)\n",
    "\n",
    "    return flair_result\n",
    "\n",
    "\n",
    "# Flair_Word_Embeddings\n",
    "word_embedding = flair_wordembed(data['Token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c41e0d-77f1-48ef-abd1-679bf9130776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace empty values in the list of word embeddings for words \n",
    "# we couldn't generate a word embedding for\n",
    "\n",
    "word_embedding_complete = []\n",
    "\n",
    "for i in tqdm(word_embedding):\n",
    "    try:\n",
    "        if len(i) == 0:\n",
    "            i = []\n",
    "        else:\n",
    "            i = i\n",
    "        word_embedding_complete.append(i)\n",
    "        \n",
    "    except TypeError:\n",
    "        i = []\n",
    "        word_embedding_complete.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert list to dataframe\n",
    "word_embedding_df = pd.DataFrame(word_embedding_complete)\n",
    "word_embedding_series = word_embedding_df.apply(pd.Series)\n",
    "\n",
    "# We concat the annotated data with the linguistic features\n",
    "data = pd.concat([data, word_embedding_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Optionally the data can be saved to create a checkpoint\n",
    "\n",
    "data.to_csv('data_features_full_wordembedding_flair.csv', index = False)\n",
    "\n",
    "data = pd.read_csv('data_features_full_wordembedding_flair.csv', na_values=['nan'])\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Replace NaN values with a \"0\"\n",
    "\n",
    "data = data.replace(np.nan, '0', regex=True)\n",
    "\n",
    "# We drop the token, as it is no longer needed for prediction\n",
    "data.drop('Token', axis=1, inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 80% / 20% split\n",
    "# Train, Test = train_test_split(data1, test_size=0.2, shuffle=False)\n",
    "\n",
    "X = data.drop(['Label'],axis=1).values # independant features\n",
    "y = data['Label'].values # dependant variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data to save memory\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_iterations = 1000000000\n",
    "\n",
    "classifier = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "cv_classifier = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee7068-0f0a-4b42-8d7c-c4f87561bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Baseline\n",
    "\n",
    "clf = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9837b-2752-43b6-b0a2-7070e55216c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - Baseline\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_baseline.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_baseline.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ad413-3e48-4798-a685-7c6d08627458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Baseline\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"Baseline\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = LogisticRegression(solver='newton-cg', random_state=seed, max_iter=max_iterations)\n",
    "scores_LR = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "LR_avg_precision = mean(scores_LR['test_precision_macro'])\n",
    "LR_avg_recall = mean(scores_LR['test_recall_macro'])\n",
    "LR_avg_f1 = mean(scores_LR['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"LR\")\n",
    "cv_precision.append(LR_avg_precision)\n",
    "cv_recall.append(LR_avg_recall)\n",
    "cv_f1.append(LR_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c7000-3aa1-4cd3-b4d7-406d92ed0cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - LR\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_lr.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_lr.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Logistic Regression\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"LR\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "# Cross validation\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "scores_DT = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "DT_avg_precision = mean(scores_DT['test_precision_macro'])\n",
    "DT_avg_recall = mean(scores_DT['test_recall_macro'])\n",
    "DT_avg_f1 = mean(scores_DT['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"DT\")\n",
    "cv_precision.append(DT_avg_precision)\n",
    "cv_recall.append(DT_avg_recall)\n",
    "cv_f1.append(DT_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f777e8e-085c-4c5d-85a6-1acb6606796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - DT\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_dt.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_dt.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Decision Tree\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"DT\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "clf = GaussianNB()\n",
    "scores_NB = cross_validate(clf, X_train, y_train, scoring = scoring, cv=10, n_jobs=-1)\n",
    "NB_avg_precision = mean(scores_NB['test_precision_macro'])\n",
    "NB_avg_recall = mean(scores_NB['test_recall_macro'])\n",
    "NB_avg_f1 = mean(scores_NB['test_f1_macro'])\n",
    "\n",
    "cv_classifier.append(\"NB\")\n",
    "cv_precision.append(NB_avg_precision)\n",
    "cv_recall.append(NB_avg_recall)\n",
    "cv_f1.append(NB_avg_f1)\n",
    "\n",
    "# Model fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd3ce4-7b6b-490a-9084-3c46422d434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally the data can be saved to create a checkpoint - NB\n",
    "\n",
    "import pickle\n",
    "\n",
    "f = open('flair_nb.pckl', 'wb')\n",
    "pickle.dump(clf, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_nb.pckl', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Naive Bayes\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1_score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "classifier.append(\"NB\")\n",
    "accuracy.append(accuracy_score(y_test, y_pred))\n",
    "precision.append(precision_score(y_test, y_pred, average='macro',zero_division=0))\n",
    "recall.append(recall_score(y_test, y_pred, average='macro'))\n",
    "f1.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4812315-30d2-4e25-b01e-87df2ff6fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = pd.DataFrame(zip(cv_classifier, cv_precision, cv_recall, cv_f1), columns = ['CV_Classifier', 'CV_Precision', 'CV_Recall', 'CV_F1-score'])\n",
    "results_cv = results_cv.sort_values(by = \"CV_F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_cv_results.pckl', 'wb')\n",
    "pickle.dump(results_cv, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_cv_results.pckl', 'rb')\n",
    "results_cv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628dadb-d645-4ef6-a2e3-2934b492fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(zip(classifier, accuracy, precision, recall, f1), columns = ['Classifier', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "results = results.sort_values(by = \"F1-score\", ascending = False)\n",
    "\n",
    "f = open('flair_results.pckl', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()\n",
    "\n",
    "f = open('flair_results.pckl', 'rb')\n",
    "results = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa68a9-3135-44dd-b3f7-a71839b6dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results dataframe\n",
    "\n",
    "results.to_csv('flair_results.csv', index = False)\n",
    "results_cv.to_csv('flair_cv_results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
